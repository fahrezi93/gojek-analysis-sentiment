{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c132ac",
   "metadata": {},
   "source": [
    "## üîß 1. Setup & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages jika belum ada\n",
    "# !pip install torch transformers scikit-learn pandas numpy matplotlib seaborn tqdm\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "print('=' * 60)\n",
    "print('üñ•Ô∏è  SYSTEM INFO')\n",
    "print('=' * 60)\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'Platform: {platform.system()} {platform.release()}')\n",
    "print()\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    print('‚úÖ CUDA is available!')\n",
    "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'   CUDA Version: {torch.version.cuda}')\n",
    "    print(f'   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('‚ö†Ô∏è CUDA not available, using CPU')\n",
    "    print('   Training will be SLOW!')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'\\nüéÆ Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f869daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, \n",
    "    classification_report, confusion_matrix, f1_score\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print('‚úì Libraries imported')\n",
    "print(f'‚úì Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126b05d",
   "metadata": {},
   "source": [
    "## üìä 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data dari folder data/\n",
    "DATA_PATH = 'data/gojek_reviews_final_augmented.csv'\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f'‚ùå File tidak ditemukan: {DATA_PATH}')\n",
    "    print('\\nüìÅ Files yang ada:')\n",
    "    if os.path.exists('data'):\n",
    "        for f in os.listdir('data'):\n",
    "            print(f'   - data/{f}')\n",
    "else:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    \n",
    "    print('=' * 60)\n",
    "    print('üìä DATA OVERVIEW')\n",
    "    print('=' * 60)\n",
    "    print(f'Total samples: {len(df):,}')\n",
    "    print(f'Columns: {df.columns.tolist()}')\n",
    "    print(f'\\nüìà Sentiment Distribution:')\n",
    "    print(df['sentiment'].value_counts())\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    colors = {'negative': '#e74c3c', 'neutral': '#95a5a6', 'positive': '#2ecc71'}\n",
    "    counts = df['sentiment'].value_counts()\n",
    "    bars = ax.bar(counts.index, counts.values, color=[colors[s] for s in counts.index])\n",
    "    ax.set_title('Sentiment Distribution')\n",
    "    ax.set_ylabel('Count')\n",
    "    for bar, count in zip(bars, counts.values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, \n",
    "                str(count), ha='center', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59c0e0",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è 3. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ebe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is already balanced\n",
    "counts = df['sentiment'].value_counts()\n",
    "min_count = counts.min()\n",
    "max_count = counts.max()\n",
    "\n",
    "if (max_count - min_count) / max_count < 0.1:\n",
    "    print('‚úì Data sudah balanced!')\n",
    "    df_balanced = df.copy()\n",
    "else:\n",
    "    print('‚ö†Ô∏è Melakukan undersampling...')\n",
    "    df_balanced = pd.DataFrame()\n",
    "    for sentiment in ['negative', 'neutral', 'positive']:\n",
    "        df_class = df[df['sentiment'] == sentiment]\n",
    "        df_sampled = resample(df_class, replace=False, n_samples=min_count, random_state=42)\n",
    "        df_balanced = pd.concat([df_balanced, df_sampled])\n",
    "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f'\\nüìä Data untuk training: {len(df_balanced):,} samples')\n",
    "print(df_balanced['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76450b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping\n",
    "LABEL_MAP = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "LABEL_NAMES = ['negative', 'neutral', 'positive']\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "df_balanced['label'] = df_balanced['sentiment'].map(LABEL_MAP)\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_balanced, test_size=0.3, random_state=42, stratify=df_balanced['label']\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, random_state=42, stratify=temp_df['label']\n",
    ")\n",
    "\n",
    "print('=' * 60)\n",
    "print('üìÇ DATA SPLITS')\n",
    "print('=' * 60)\n",
    "print(f'Train: {len(train_df):,} samples ({len(train_df)/len(df_balanced)*100:.1f}%)')\n",
    "print(f'Val:   {len(val_df):,} samples ({len(val_df)/len(df_balanced)*100:.1f}%)')\n",
    "print(f'Test:  {len(test_df):,} samples ({len(test_df)/len(df_balanced)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40d14b1",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2411265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HYPERPARAMETERS ===\n",
    "# Optimized untuk menghindari overfitting\n",
    "\n",
    "CONFIG = {\n",
    "    # Model\n",
    "    'model_name': 'indobenchmark/indobert-base-p1',\n",
    "    'max_length': 128,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 32,\n",
    "    'epochs': 30,\n",
    "    'learning_rate': 5e-6,  # Sangat kecil untuk hindari overfitting\n",
    "    \n",
    "    # Anti-Overfitting\n",
    "    'dropout_rate': 0.6,\n",
    "    'attention_dropout': 0.3,\n",
    "    'weight_decay': 0.05,\n",
    "    'label_smoothing': 0.2,\n",
    "    'warmup_ratio': 0.15,\n",
    "    'max_grad_norm': 0.5,\n",
    "    'early_stopping_patience': 7,\n",
    "    \n",
    "    # Data Augmentation\n",
    "    'word_dropout_prob': 0.2,\n",
    "    \n",
    "    # Layer Freezing\n",
    "    'freeze_layers': 9,  # Freeze 9 dari 12 layer\n",
    "    \n",
    "    # R-Drop\n",
    "    'rdrop_alpha': 0.5,\n",
    "}\n",
    "\n",
    "print('=' * 60)\n",
    "print('‚öôÔ∏è  CONFIGURATION')\n",
    "print('=' * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d303e",
   "metadata": {},
   "source": [
    "## üì¶ 5. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef18596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "print(f'‚úì Tokenizer loaded: {CONFIG[\"model_name\"]}')\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"Dataset dengan augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128, \n",
    "                 augment=False, word_dropout_prob=0.2):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.augment = augment\n",
    "        self.word_dropout_prob = word_dropout_prob\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def _augment_text(self, text):\n",
    "        if not self.augment:\n",
    "            return text\n",
    "        \n",
    "        text = str(text)\n",
    "        words = text.split()\n",
    "        \n",
    "        if len(words) <= 3:\n",
    "            return text\n",
    "        \n",
    "        aug_type = random.random()\n",
    "        \n",
    "        if aug_type < 0.3:\n",
    "            # Word dropout\n",
    "            words = [w for w in words if random.random() > self.word_dropout_prob]\n",
    "        elif aug_type < 0.5:\n",
    "            # Word swap\n",
    "            if len(words) > 2:\n",
    "                idx = random.randint(0, len(words) - 2)\n",
    "                words[idx], words[idx + 1] = words[idx + 1], words[idx]\n",
    "        elif aug_type < 0.7:\n",
    "            # Random deletion\n",
    "            if len(words) > 4:\n",
    "                del_idx = random.randint(0, len(words) - 1)\n",
    "                words.pop(del_idx)\n",
    "        \n",
    "        return ' '.join(words) if words else text\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self._augment_text(self.texts[idx])\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            str(text),\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = SentimentDataset(\n",
    "    train_df['content_clean'].values,\n",
    "    train_df['label'].values,\n",
    "    tokenizer,\n",
    "    max_length=CONFIG['max_length'],\n",
    "    augment=True,\n",
    "    word_dropout_prob=CONFIG['word_dropout_prob']\n",
    ")\n",
    "\n",
    "val_dataset = SentimentDataset(\n",
    "    val_df['content_clean'].values,\n",
    "    val_df['label'].values,\n",
    "    tokenizer,\n",
    "    max_length=CONFIG['max_length'],\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "test_dataset = SentimentDataset(\n",
    "    test_df['content_clean'].values,\n",
    "    test_df['label'].values,\n",
    "    tokenizer,\n",
    "    max_length=CONFIG['max_length'],\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print(f'\\n‚úì Datasets created:')\n",
    "print(f'  Train: {len(train_dataset)} samples, {len(train_loader)} batches')\n",
    "print(f'  Val:   {len(val_dataset)} samples, {len(val_loader)} batches')\n",
    "print(f'  Test:  {len(test_dataset)} samples, {len(test_loader)} batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496c97",
   "metadata": {},
   "source": [
    "## üß† 6. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndoBERTSentimentClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    IndoBERT dengan regularisasi maksimal:\n",
    "    - Freeze 9/12 layer BERT\n",
    "    - Multiple dropout\n",
    "    - Simple classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name, num_classes, dropout_rate=0.6, \n",
    "                 attention_dropout=0.3, freeze_layers=9):\n",
    "        super(IndoBERTSentimentClassifier, self).__init__()\n",
    "        \n",
    "        # Load pretrained BERT\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # Freeze embeddings\n",
    "        for param in self.bert.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Freeze first N encoder layers\n",
    "        for i in range(freeze_layers):\n",
    "            for param in self.bert.encoder.layer[i].parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Add dropout to attention in unfrozen layers\n",
    "        for i in range(freeze_layers, 12):\n",
    "            self.bert.encoder.layer[i].attention.self.dropout = nn.Dropout(attention_dropout)\n",
    "            self.bert.encoder.layer[i].attention.output.dropout = nn.Dropout(attention_dropout)\n",
    "        \n",
    "        print(f'‚úì Froze embeddings and first {freeze_layers} encoder layers')\n",
    "        print(f'  Only layers {freeze_layers}-11 are trainable (3 layers)')\n",
    "        \n",
    "        # Regularization\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.layer_norm = nn.LayerNorm(self.hidden_size)\n",
    "        \n",
    "        # Simple classifier\n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes)\n",
    "        \n",
    "        # Initialize\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs.pooler_output\n",
    "        \n",
    "        x = self.layer_norm(pooled_output)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        if self.training:\n",
    "            x = self.dropout2(x)\n",
    "        \n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print('Loading IndoBERT model...')\n",
    "model = IndoBERTSentimentClassifier(\n",
    "    model_name=CONFIG['model_name'],\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    dropout_rate=CONFIG['dropout_rate'],\n",
    "    attention_dropout=CONFIG['attention_dropout'],\n",
    "    freeze_layers=CONFIG['freeze_layers']\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "print(f'\\n‚úì Model loaded to {device}')\n",
    "print(f'  Total parameters: {total_params:,}')\n",
    "print(f'  Trainable: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)')\n",
    "print(f'  Frozen: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e17cac",
   "metadata": {},
   "source": [
    "## üìâ 7. Loss, Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function dengan label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=CONFIG['label_smoothing'])\n",
    "\n",
    "# Optimizer - hanya untuk trainable parameters\n",
    "no_decay = ['bias', 'LayerNorm.weight', 'layer_norm.weight']\n",
    "trainable_params_list = [(n, p) for n, p in model.named_parameters() if p.requires_grad]\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in trainable_params_list if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': CONFIG['weight_decay']\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in trainable_params_list if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=CONFIG['learning_rate'])\n",
    "\n",
    "# Scheduler\n",
    "total_steps = len(train_loader) * CONFIG['epochs']\n",
    "warmup_steps = int(total_steps * CONFIG['warmup_ratio'])\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f'‚úì Optimizer: AdamW (lr={CONFIG[\"learning_rate\"]}, wd={CONFIG[\"weight_decay\"]})')\n",
    "print(f'‚úì Scheduler: Linear warmup ({warmup_steps} warmup, {total_steps} total)')\n",
    "print(f'‚úì Loss: CrossEntropy with label_smoothing={CONFIG[\"label_smoothing\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ed0e8",
   "metadata": {},
   "source": [
    "## üèãÔ∏è 8. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821bd204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kl_loss(p, q):\n",
    "    \"\"\"KL divergence for R-Drop\"\"\"\n",
    "    p_loss = F.kl_div(F.log_softmax(p, dim=-1), F.softmax(q, dim=-1), reduction='batchmean')\n",
    "    q_loss = F.kl_div(F.log_softmax(q, dim=-1), F.softmax(p, dim=-1), reduction='batchmean')\n",
    "    return (p_loss + q_loss) / 2\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, scheduler, device, \n",
    "                max_grad_norm, rdrop_alpha=0.5):\n",
    "    \"\"\"Train dengan R-Drop regularization\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Training', leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # R-Drop: 2 forward passes\n",
    "        logits1 = model(input_ids, attention_mask)\n",
    "        logits2 = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Cross entropy loss\n",
    "        ce_loss = (criterion(logits1, labels) + criterion(logits2, labels)) / 2\n",
    "        \n",
    "        # KL divergence loss\n",
    "        kl_loss = compute_kl_loss(logits1, logits2)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = ce_loss + rdrop_alpha * kl_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        avg_logits = (logits1 + logits2) / 2\n",
    "        preds = torch.argmax(avg_logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping dengan gap monitoring\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=7, min_delta=0.001, mode='max', max_gap=0.08):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.max_gap = max_gap\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "        self.best_gap = float('inf')\n",
    "    \n",
    "    def __call__(self, score, model, train_score=None):\n",
    "        if self.mode == 'max':\n",
    "            is_improvement = self.best_score is None or score > self.best_score + self.min_delta\n",
    "        else:\n",
    "            is_improvement = self.best_score is None or score < self.best_score - self.min_delta\n",
    "        \n",
    "        if is_improvement:\n",
    "            self.best_score = score\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "            if train_score is not None:\n",
    "                self.best_gap = train_score - score\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        \n",
    "        return self.early_stop\n",
    "\n",
    "print('‚úì Training functions defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c1b80a",
   "metadata": {},
   "source": [
    "## üöÄ 9. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
    "    'gap': []\n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=CONFIG['early_stopping_patience'], \n",
    "    mode='max',\n",
    "    max_gap=0.08\n",
    ")\n",
    "\n",
    "print('=' * 60)\n",
    "print('üöÄ TRAINING STARTED')\n",
    "print('=' * 60)\n",
    "print(f'Device: {device}')\n",
    "print(f'Epochs: {CONFIG[\"epochs\"]} | Patience: {CONFIG[\"early_stopping_patience\"]}')\n",
    "print(f'LR: {CONFIG[\"learning_rate\"]} | Batch: {CONFIG[\"batch_size\"]}')\n",
    "print(f'Frozen Layers: {CONFIG[\"freeze_layers\"]}/12 | Dropout: {CONFIG[\"dropout_rate\"]}')\n",
    "print('-' * 60)\n",
    "\n",
    "best_val_f1 = 0\n",
    "best_epoch = 0\n",
    "best_gap = float('inf')\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = datetime.now()\n",
    "    print(f'\\nüìç Epoch {epoch + 1}/{CONFIG[\"epochs\"]}')\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc, train_f1 = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, scheduler, \n",
    "        device, CONFIG['max_grad_norm'], CONFIG['rdrop_alpha']\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_f1, _, _ = evaluate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    gap = train_acc - val_acc\n",
    "    epoch_time = datetime.now() - epoch_start\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    history['gap'].append(gap)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f'  Train - Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}')\n",
    "    print(f'  Val   - Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Track best\n",
    "    if val_f1 > best_val_f1 and gap < 0.10:\n",
    "        best_val_f1 = val_f1\n",
    "        best_epoch = epoch + 1\n",
    "        best_gap = gap\n",
    "        print(f'  ‚≠ê New best! F1: {val_f1:.4f}, Gap: {gap*100:.2f}%')\n",
    "    \n",
    "    # Gap status\n",
    "    gap_status = '‚úÖ Good' if gap < 0.05 else '‚ö° OK' if gap < 0.10 else '‚ö†Ô∏è High'\n",
    "    print(f'  üìä Gap: {gap*100:.2f}% {gap_status} | Time: {epoch_time}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if early_stopping(val_f1, model, train_acc):\n",
    "        print(f'\\nüõë Early stopping at epoch {epoch + 1}')\n",
    "        break\n",
    "\n",
    "total_time = datetime.now() - start_time\n",
    "\n",
    "# Load best model\n",
    "if early_stopping.best_model is not None:\n",
    "    model.load_state_dict(early_stopping.best_model)\n",
    "\n",
    "print(f'\\n‚úì Training completed in {total_time}')\n",
    "print(f'  Best epoch: {best_epoch}')\n",
    "print(f'  Best Val F1: {best_val_f1:.4f}')\n",
    "print(f'  Best Gap: {best_gap*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f28c01",
   "metadata": {},
   "source": [
    "## üìà 10. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59655b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(epochs_range, history['train_loss'], 'b-o', label='Train')\n",
    "axes[0, 0].plot(epochs_range, history['val_loss'], 'r-s', label='Val')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training & Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(epochs_range, history['train_acc'], 'b-o', label='Train')\n",
    "axes[0, 1].plot(epochs_range, history['val_acc'], 'r-s', label='Val')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].set_title('Training & Validation Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "axes[1, 0].plot(epochs_range, history['train_f1'], 'b-o', label='Train')\n",
    "axes[1, 0].plot(epochs_range, history['val_f1'], 'r-s', label='Val')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('F1 Score')\n",
    "axes[1, 0].set_title('Training & Validation F1 Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gap\n",
    "axes[1, 1].plot(epochs_range, [g*100 for g in history['gap']], 'g-o')\n",
    "axes[1, 1].axhline(y=5, color='orange', linestyle='--', label='Good threshold (5%)')\n",
    "axes[1, 1].axhline(y=10, color='red', linestyle='--', label='Warning threshold (10%)')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Train-Val Gap (%)')\n",
    "axes[1, 1].set_title('Overfitting Monitor (Train-Val Gap)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('‚úì Saved: training_history.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424dd31",
   "metadata": {},
   "source": [
    "## üß™ 11. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print('=' * 60)\n",
    "print('üß™ TEST SET EVALUATION')\n",
    "print('=' * 60)\n",
    "print(f'Test Accuracy: {test_acc*100:.2f}%')\n",
    "print(f'Test F1 Score: {test_f1*100:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print('\\nüìä Classification Report:')\n",
    "print(classification_report(test_labels, test_preds, target_names=LABEL_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=LABEL_NAMES, yticklabels=LABEL_NAMES, ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('Confusion Matrix (Counts)')\n",
    "\n",
    "# Percentages\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.1f', cmap='Blues',\n",
    "            xticklabels=LABEL_NAMES, yticklabels=LABEL_NAMES, ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_title('Confusion Matrix (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('‚úì Saved: confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de2423e",
   "metadata": {},
   "source": [
    "## üíæ 12. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = 'models/indobert_sentiment_3class.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'label_map': LABEL_MAP,\n",
    "    'label_names': LABEL_NAMES,\n",
    "    'test_accuracy': test_acc,\n",
    "    'test_f1': test_f1,\n",
    "    'best_val_f1': best_val_f1,\n",
    "    'best_gap': best_gap,\n",
    "    'history': history,\n",
    "}, model_path)\n",
    "print(f'‚úì Model saved: {model_path}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('models/tokenizer')\n",
    "print(f'‚úì Tokenizer saved: models/tokenizer/')\n",
    "\n",
    "# Save history\n",
    "with open('models/training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(f'‚úì History saved: models/training_history.json')\n",
    "\n",
    "# List saved files\n",
    "print('\\nüìÅ Saved files:')\n",
    "for root, dirs, files in os.walk('models'):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file)\n",
    "        size = os.path.getsize(filepath) / (1024*1024)\n",
    "        print(f'   {filepath} ({size:.2f} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f5ead6",
   "metadata": {},
   "source": [
    "## üîÆ 13. Inference Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device, label_names):\n",
    "    \"\"\"Predict sentiment untuk satu teks\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "    \n",
    "    return {\n",
    "        'sentiment': label_names[pred],\n",
    "        'confidence': probs[0][pred].item(),\n",
    "        'probabilities': {\n",
    "            label_names[i]: probs[0][i].item() \n",
    "            for i in range(len(label_names))\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test\n",
    "test_reviews = [\n",
    "    \"Aplikasi gojek sangat membantu, driver ramah dan cepat\",\n",
    "    \"Driver nya lama banget, udah nunggu 1 jam gak datang\",\n",
    "    \"Biasa aja sih aplikasinya\",\n",
    "    \"Pelayanan buruk, tidak akan pakai lagi\",\n",
    "    \"Mantap, makanan sampai dengan selamat dan masih hangat\",\n",
    "]\n",
    "\n",
    "print('=' * 60)\n",
    "print('üîÆ INFERENCE DEMO')\n",
    "print('=' * 60)\n",
    "\n",
    "for review in test_reviews:\n",
    "    result = predict_sentiment(review, model, tokenizer, device, LABEL_NAMES)\n",
    "    emoji = {'negative': 'üò†', 'neutral': 'üòê', 'positive': 'üòä'}[result['sentiment']]\n",
    "    print(f'\\nüìù \"{review[:50]}...\"' if len(review) > 50 else f'\\nüìù \"{review}\"')\n",
    "    print(f'   {emoji} {result[\"sentiment\"].upper()} ({result[\"confidence\"]*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5541f9c",
   "metadata": {},
   "source": [
    "## üìä 14. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gap = history['train_acc'][-1] - history['val_acc'][-1]\n",
    "min_gap = min(history['gap'])\n",
    "\n",
    "print('=' * 60)\n",
    "print('üìä FINAL SUMMARY')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f'''\n",
    "üéØ MODEL PERFORMANCE:\n",
    "   ‚Ä¢ Test Accuracy: {test_acc*100:.2f}%\n",
    "   ‚Ä¢ Test F1 Score: {test_f1*100:.2f}%\n",
    "   ‚Ä¢ Best Val F1: {best_val_f1*100:.2f}%\n",
    "\n",
    "üìà OVERFITTING CHECK:\n",
    "   ‚Ä¢ Final Gap: {final_gap*100:.2f}%\n",
    "   ‚Ä¢ Best Gap: {best_gap*100:.2f}%\n",
    "   ‚Ä¢ Status: {\"‚úÖ Good\" if final_gap < 0.05 else \"‚ö†Ô∏è Check\" if final_gap < 0.10 else \"‚ùå Overfitting\"}\n",
    "\n",
    "‚öôÔ∏è TECHNIQUES USED:\n",
    "   ‚Ä¢ Layer Freezing: {CONFIG['freeze_layers']}/12\n",
    "   ‚Ä¢ Dropout: {CONFIG['dropout_rate']}\n",
    "   ‚Ä¢ R-Drop Alpha: {CONFIG['rdrop_alpha']}\n",
    "   ‚Ä¢ Weight Decay: {CONFIG['weight_decay']}\n",
    "   ‚Ä¢ Label Smoothing: {CONFIG['label_smoothing']}\n",
    "   ‚Ä¢ Learning Rate: {CONFIG['learning_rate']}\n",
    "\n",
    "üíæ SAVED FILES:\n",
    "   ‚Ä¢ models/indobert_sentiment_3class.pt\n",
    "   ‚Ä¢ models/tokenizer/\n",
    "   ‚Ä¢ models/training_history.json\n",
    "   ‚Ä¢ training_history.png\n",
    "   ‚Ä¢ confusion_matrix.png\n",
    "''')\n",
    "\n",
    "if test_acc >= 0.75 and final_gap < 0.05:\n",
    "    print('üéâ EXCELLENT! Model has good accuracy and generalization!')\n",
    "elif test_acc >= 0.75:\n",
    "    print('‚ö†Ô∏è Good accuracy but watch for overfitting.')\n",
    "elif final_gap < 0.05:\n",
    "    print('‚úÖ Good generalization but accuracy could improve.')\n",
    "else:\n",
    "    print('‚ùå Consider adjusting hyperparameters.')\n",
    "\n",
    "print('=' * 60)\n",
    "print('‚úÖ Training completed!')\n",
    "print('=' * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
