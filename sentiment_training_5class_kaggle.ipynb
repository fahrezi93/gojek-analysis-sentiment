{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SETUP KAGGLE ENVIRONMENT\n",
    "# ============================================\n",
    "\n",
    "# Install transformers\n",
    "!pip install transformers -q\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Check GPU\n",
    "print('=' * 50)\n",
    "print('ENVIRONMENT CHECK')\n",
    "print('=' * 50)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU Available: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "else:\n",
    "    print('WARNING: GPU not available!')\n",
    "\n",
    "# Find dataset\n",
    "KAGGLE_INPUT = '/kaggle/input'\n",
    "DATA_PATH = None\n",
    "\n",
    "print(f'\\nSearching for dataset...')\n",
    "for root, dirs, files in os.walk(KAGGLE_INPUT):\n",
    "    for f in files:\n",
    "        if '5class_clean' in f and f.endswith('.csv'):\n",
    "            DATA_PATH = os.path.join(root, f)\n",
    "            print(f'Found: {DATA_PATH}')\n",
    "            break\n",
    "\n",
    "if DATA_PATH is None:\n",
    "    print('\\nDataset not found! Please upload gojek_reviews_5class_clean.csv')\n",
    "    print('\\nAvailable files in /kaggle/input:')\n",
    "    for root, dirs, files in os.walk(KAGGLE_INPUT):\n",
    "        for f in files:\n",
    "            print(f'  - {os.path.join(root, f)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# IMPORTS\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, \n",
    "    classification_report, confusion_matrix, f1_score\n",
    ")\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429773dc",
   "metadata": {},
   "source": [
    "## ðŸ“Š 1. Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a76e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Label mapping untuk 5 kelas\n",
    "LABEL_MAP = {\n",
    "    'sangat_negatif': 0,\n",
    "    'negatif': 1,\n",
    "    'netral': 2,\n",
    "    'positif': 3,\n",
    "    'sangat_positif': 4\n",
    "}\n",
    "LABEL_NAMES = ['sangat_negatif', 'negatif', 'netral', 'positif', 'sangat_positif']\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# Create label column\n",
    "df['label'] = df['sentiment_label'].map(LABEL_MAP)\n",
    "\n",
    "print('=' * 60)\n",
    "print('DATA OVERVIEW')\n",
    "print('=' * 60)\n",
    "print(f'Total samples: {len(df):,}')\n",
    "print(f'\\nColumns: {df.columns.tolist()}')\n",
    "print(f'\\nSentiment Distribution:')\n",
    "print(df['sentiment_label'].value_counts())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = ['#e74c3c', '#f39c12', '#95a5a6', '#3498db', '#2ecc71']\n",
    "sentiment_counts = df['sentiment_label'].value_counts().reindex(LABEL_NAMES)\n",
    "\n",
    "axes[0].bar(range(5), sentiment_counts.values, color=colors)\n",
    "axes[0].set_xticks(range(5))\n",
    "axes[0].set_xticklabels(LABEL_NAMES, rotation=45, ha='right')\n",
    "axes[0].set_title('Sentiment Distribution (5 Classes)')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "axes[1].pie(sentiment_counts.values, labels=LABEL_NAMES, autopct='%1.1f%%', colors=colors)\n",
    "axes[1].set_title('Sentiment Percentage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sample reviews\n",
    "print('\\nSample Reviews:')\n",
    "for label_name in LABEL_NAMES:\n",
    "    sample = df[df['sentiment_label'] == label_name].sample(1).iloc[0]\n",
    "    print(f'\\n[{label_name.upper()}] Rating {sample[\"rating\"]}:')\n",
    "    print(f'   \"{sample[\"review\"][:80]}...\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba20cc1",
   "metadata": {},
   "source": [
    "## âš–ï¸ 2. Data Split (Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split: Train (70%), Val (15%), Test (15%)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, random_state=42, stratify=temp_df['label']\n",
    ")\n",
    "\n",
    "print('=' * 60)\n",
    "print('DATA SPLIT')\n",
    "print('=' * 60)\n",
    "print(f'Training set: {len(train_df):,} samples ({len(train_df)/len(df)*100:.1f}%)')\n",
    "print(f'Validation set: {len(val_df):,} samples ({len(val_df)/len(df)*100:.1f}%)')\n",
    "print(f'Test set: {len(test_df):,} samples ({len(test_df)/len(df)*100:.1f}%)')\n",
    "\n",
    "print('\\nDistribution per split:')\n",
    "for name, data in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
    "    dist = data['label'].value_counts(normalize=True).sort_index() * 100\n",
    "    print(f'{name}: ' + ' | '.join([f'{LABEL_NAMES[i][:4]}: {dist[i]:.1f}%' for i in range(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f98ca0",
   "metadata": {},
   "source": [
    "## ðŸ”§ 3. Load IndoBERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57594a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IndoBERT tokenizer\n",
    "MODEL_NAME = 'indobenchmark/indobert-base-p1'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Analyze text lengths\n",
    "text_lengths = df['review'].apply(lambda x: len(tokenizer.encode(str(x), add_special_tokens=True)))\n",
    "\n",
    "print('=' * 60)\n",
    "print('TEXT LENGTH ANALYSIS')\n",
    "print('=' * 60)\n",
    "print(f'Min tokens: {text_lengths.min()}')\n",
    "print(f'Max tokens: {text_lengths.max()}')\n",
    "print(f'Mean tokens: {text_lengths.mean():.1f}')\n",
    "print(f'95th percentile: {text_lengths.quantile(0.95):.0f}')\n",
    "\n",
    "MAX_LEN = min(int(text_lengths.quantile(0.95)) + 10, 128)\n",
    "print(f'\\nUsing MAX_LEN = {MAX_LEN}')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(text_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=MAX_LEN, color='r', linestyle='--', label=f'MAX_LEN = {MAX_LEN}')\n",
    "plt.xlabel('Token Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Text Lengths')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5182f32",
   "metadata": {},
   "source": [
    "## ðŸ“¦ 4. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a31bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len, augment=False):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # No augmentation - let model learn the actual data first\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(\n",
    "    train_df['review'].values, train_df['label'].values,\n",
    "    tokenizer, MAX_LEN, augment=True\n",
    ")\n",
    "val_dataset = SentimentDataset(\n",
    "    val_df['review'].values, val_df['label'].values,\n",
    "    tokenizer, MAX_LEN, augment=False\n",
    ")\n",
    "test_dataset = SentimentDataset(\n",
    "    test_df['review'].values, test_df['label'].values,\n",
    "    tokenizer, MAX_LEN, augment=False\n",
    ")\n",
    "\n",
    "# Data loaders\n",
    "# Create datasets (no augmentation for cleaner learning)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    tokenizer, MAX_LEN, augment=False\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}')\n",
    "print(f'Val batches: {len(val_loader)}')\n",
    "print(f'Test batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849acfc",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ 5. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a14c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndoBERTSentiment5Class(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=5, dropout_rate=0.1, freeze_bert_layers=0):\n",
    "        super(IndoBERTSentiment5Class, self).__init__()\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # Freeze lower BERT layers (0 = unfreeze all for better learning)\n",
    "        if freeze_bert_layers > 0:\n",
    "            for param in self.bert.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "            for i in range(freeze_bert_layers):\n",
    "                for param in self.bert.encoder.layer[i].parameters():\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        # Simpler classifier - less prone to underfitting\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(self.hidden_size, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        nn.init.zeros_(self.classifier.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Initialize model - UNFREEZE all layers for better learning\n",
    "model = IndoBERTSentiment5Class(\n",
    "    MODEL_NAME, num_classes=NUM_CLASSES, dropout_rate=0.1, freeze_bert_layers=0\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('=' * 60)\n",
    "print('MODEL ARCHITECTURE')\n",
    "print('=' * 60)\n",
    "print(f'Total parameters: {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)')\n",
    "print(f'Frozen parameters: {total_params - trainable_params:,}')\n",
    "print('\\nNote: All BERT layers are TRAINABLE for maximum learning capacity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced68c43",
   "metadata": {},
   "source": [
    "## ðŸ“‰ 6. Loss Function (Focal Loss + Label Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use simple CrossEntropyLoss with label smoothing\n",
    "# Focal Loss can cause underfitting when model hasn't learned well yet\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, num_classes=5, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        log_probs = F.log_softmax(inputs, dim=1)\n",
    "        \n",
    "        # Create smoothed labels\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(log_probs)\n",
    "            true_dist.fill_(self.smoothing / (self.num_classes - 1))\n",
    "            true_dist.scatter_(1, targets.unsqueeze(1), self.confidence)\n",
    "        \n",
    "        return torch.mean(torch.sum(-true_dist * log_probs, dim=1))\n",
    "\n",
    "# Simple CrossEntropy for initial training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print('Loss: CrossEntropyLoss (simple, effective for learning)')\n",
    "print('\\nNote: Using simple loss to help model learn better first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c70ffe",
   "metadata": {},
   "source": [
    "## âš™ï¸ 7. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - OPTIMIZED FOR BETTER LEARNING\n",
    "EPOCHS = 15  # More epochs to learn\n",
    "LEARNING_RATE = 3e-5  # Slightly higher LR\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.1\n",
    "MAX_GRAD_NORM = 1.0\n",
    "PATIENCE = 5  # More patience\n",
    "\n",
    "# Optimizer with different LR for BERT and classifier\n",
    "bert_params = list(model.bert.parameters())\n",
    "classifier_params = list(model.classifier.parameters())\n",
    "\n",
    "optimizer = AdamW([\n",
    "    {'params': bert_params, 'lr': LEARNING_RATE},\n",
    "    {'params': classifier_params, 'lr': LEARNING_RATE * 10}  # Higher LR for classifier\n",
    "], weight_decay=WEIGHT_DECAY, eps=1e-8)\n",
    "\n",
    "# Scheduler\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print('=' * 60)\n",
    "print('TRAINING CONFIG')\n",
    "print('=' * 60)\n",
    "print(f'Epochs: {EPOCHS}')\n",
    "print(f'Batch size: {BATCH_SIZE}')\n",
    "print(f'Learning rate (BERT): {LEARNING_RATE}')\n",
    "print(f'Learning rate (Classifier): {LEARNING_RATE * 10}')\n",
    "print(f'Weight decay: {WEIGHT_DECAY}')\n",
    "print(f'Warmup steps: {warmup_steps}')\n",
    "print(f'Gradient clipping: {MAX_GRAD_NORM}')\n",
    "print(f'Early stopping patience: {PATIENCE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62f927",
   "metadata": {},
   "source": [
    "## ðŸš€ 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, criterion, optimizer, scheduler, device, max_grad_norm):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    predictions, actual_labels = [], []\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc='Training', leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        actual_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    f1 = f1_score(actual_labels, predictions, average='macro')\n",
    "    \n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "def eval_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions, actual_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc='Evaluating', leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    f1 = f1_score(actual_labels, predictions, average='macro')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, predictions, actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f1ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Early Stopping\n",
    "print('=' * 60)\n",
    "print('STARTING TRAINING')\n",
    "print('=' * 60)\n",
    "\n",
    "best_val_f1 = 0\n",
    "best_model_state = None\n",
    "patience_counter = 0\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_f1': []\n",
    "}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 40)\n",
    "    \n",
    "    train_loss, train_acc, train_f1 = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, scheduler, device, MAX_GRAD_NORM\n",
    "    )\n",
    "    \n",
    "    val_loss, val_acc, val_f1, _, _ = eval_model(model, val_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    print(f'Train - Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}')\n",
    "    print(f'Val   - Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Overfitting check\n",
    "    overfit_gap = train_acc - val_acc\n",
    "    if overfit_gap > 0.1:\n",
    "        print(f'WARNING: Overfitting detected! Gap: {overfit_gap:.4f}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        patience_counter = 0\n",
    "        print(f'New best model! Val F1: {val_f1:.4f}')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'No improvement. Patience: {patience_counter}/{PATIENCE}')\n",
    "        \n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f'\\nEarly stopping at epoch {epoch + 1}')\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f'\\nLoaded best model with Val F1: {best_val_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e07c907",
   "metadata": {},
   "source": [
    "## ðŸ“Š 9. Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(epochs_range, history['train_loss'], 'b-o', label='Train')\n",
    "axes[0].plot(epochs_range, history['val_loss'], 'r-o', label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(epochs_range, history['train_acc'], 'b-o', label='Train')\n",
    "axes[1].plot(epochs_range, history['val_acc'], 'r-o', label='Val')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# F1\n",
    "axes[2].plot(epochs_range, history['train_f1'], 'b-o', label='Train')\n",
    "axes[2].plot(epochs_range, history['val_f1'], 'r-o', label='Val')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].set_title('F1 Score')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_5class.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Overfitting analysis\n",
    "gap = history['train_acc'][-1] - history['val_acc'][-1]\n",
    "print('\\nOVERFITTING ANALYSIS')\n",
    "print('=' * 40)\n",
    "print(f'Final Train Acc: {history[\"train_acc\"][-1]:.4f}')\n",
    "print(f'Final Val Acc: {history[\"val_acc\"][-1]:.4f}')\n",
    "print(f'Gap: {gap:.4f}')\n",
    "print(f'Status: {\"NOT Overfitting\" if gap < 0.05 else \"Check overfitting\" if gap < 0.1 else \"OVERFITTING!\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b179e9",
   "metadata": {},
   "source": [
    "## ðŸ§ª 10. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b10a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print('=' * 60)\n",
    "print('TEST SET EVALUATION')\n",
    "print('=' * 60)\n",
    "\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = eval_model(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f'\\nTest Results:')\n",
    "print(f'  Loss: {test_loss:.4f}')\n",
    "print(f'  Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)')\n",
    "print(f'  Macro F1: {test_f1:.4f}')\n",
    "\n",
    "print('\\nCLASSIFICATION REPORT')\n",
    "print('=' * 60)\n",
    "print(classification_report(test_labels, test_preds, target_names=LABEL_NAMES, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9caf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=LABEL_NAMES, yticklabels=LABEL_NAMES, ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('Confusion Matrix (Counts)')\n",
    "\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=LABEL_NAMES, yticklabels=LABEL_NAMES, ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_title('Confusion Matrix (Normalized)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_5class.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "print('\\nPER-CLASS ACCURACY')\n",
    "print('=' * 40)\n",
    "for i, label in enumerate(LABEL_NAMES):\n",
    "    acc = cm[i, i] / cm[i].sum()\n",
    "    print(f'{label}: {acc:.2%} ({cm[i, i]}/{cm[i].sum()})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027412e7",
   "metadata": {},
   "source": [
    "## ðŸ’¾ 11. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e27d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to Kaggle output\n",
    "OUTPUT_DIR = '/kaggle/working'\n",
    "\n",
    "model_path = f'{OUTPUT_DIR}/indobert_sentiment_5class_best.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'model_name': MODEL_NAME,\n",
    "        'num_classes': NUM_CLASSES,\n",
    "        'max_len': MAX_LEN,\n",
    "        'label_map': LABEL_MAP,\n",
    "        'label_names': LABEL_NAMES\n",
    "    },\n",
    "    'training_history': history,\n",
    "    'test_metrics': {'accuracy': test_acc, 'f1_score': test_f1, 'loss': test_loss}\n",
    "}, model_path)\n",
    "\n",
    "print(f'Model saved to: {model_path}')\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'max_len': MAX_LEN,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs_trained': len(history['train_loss']),\n",
    "    'test_accuracy': test_acc,\n",
    "    'test_f1': test_f1,\n",
    "    'label_map': LABEL_MAP,\n",
    "    'label_names': LABEL_NAMES\n",
    "}\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/training_config_5class.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f'Config saved to: {OUTPUT_DIR}/training_config_5class.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae5d12",
   "metadata": {},
   "source": [
    "## ðŸ”® 12. Prediction Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb30808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device, max_len=MAX_LEN):\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text, add_special_tokens=True, max_length=max_len,\n",
    "        padding='max_length', truncation=True,\n",
    "        return_attention_mask=True, return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probs, dim=1)\n",
    "    \n",
    "    return LABEL_NAMES[predicted.item()], confidence.item(), \\\n",
    "           {name: probs[0][i].item() for i, name in enumerate(LABEL_NAMES)}\n",
    "\n",
    "# Test predictions\n",
    "print('=' * 60)\n",
    "print('SAMPLE PREDICTIONS')\n",
    "print('=' * 60)\n",
    "\n",
    "test_texts = [\n",
    "    \"Aplikasi ini sangat bagus dan membantu sekali!\",\n",
    "    \"Lumayan lah, cukup membantu\",\n",
    "    \"Biasa aja, tidak ada yang istimewa\",\n",
    "    \"Kurang bagus, sering error\",\n",
    "    \"Aplikasi sampah! Sangat mengecewakan!\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    label, conf, probs = predict_sentiment(text, model, tokenizer, device)\n",
    "    print(f'\\n\"{text[:50]}...\"')\n",
    "    print(f'  -> {label.upper()} ({conf:.2%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd5cf5",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ 13. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1fe4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('FINAL SUMMARY')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f'''\n",
    "MODEL PERFORMANCE:\n",
    "  - Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\n",
    "  - Test Macro F1: {test_f1:.4f}\n",
    "\n",
    "TRAINING OPTIMIZATIONS APPLIED:\n",
    "  - Full BERT fine-tuning (all layers trainable)\n",
    "  - Simple CrossEntropyLoss (better initial learning)\n",
    "  - Differential Learning Rates (BERT: 3e-5, Classifier: 3e-4)\n",
    "  - Larger Batch Size (32)\n",
    "  - More Epochs (15) with patience (5)\n",
    "  - Lower Dropout (0.1)\n",
    "  - Simpler classifier head\n",
    "  - Weight Decay (0.01)\n",
    "  - Learning Rate Warmup\n",
    "  - Gradient Clipping (1.0)\n",
    "\n",
    "OVERFITTING CHECK:\n",
    "  - Train Acc: {history[\"train_acc\"][-1]:.4f}\n",
    "  - Val Acc: {history[\"val_acc\"][-1]:.4f}\n",
    "  - Gap: {history[\"train_acc\"][-1] - history[\"val_acc\"][-1]:.4f}\n",
    "  - Status: {\"Good\" if abs(history[\"train_acc\"][-1] - history[\"val_acc\"][-1]) < 0.1 else \"Check!\"}\n",
    "\n",
    "SAVED FILES:\n",
    "  - indobert_sentiment_5class_best.pt\n",
    "  - training_config_5class.json\n",
    "  - training_history_5class.png\n",
    "  - confusion_matrix_5class.png\n",
    "''')\n",
    "\n",
    "print('Training Complete!')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
