{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e9dcf3",
   "metadata": {},
   "source": [
    "## üîß 1. Setup & System Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e35e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages jika belum ada\n",
    "# !pip install torch transformers scikit-learn pandas numpy matplotlib seaborn tqdm psutil\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "print('=' * 60)\n",
    "print('üñ•Ô∏è  SYSTEM INFO - CPU MODE')\n",
    "print('=' * 60)\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'Platform: {platform.system()} {platform.release()}')\n",
    "print()\n",
    "\n",
    "# CPU Info\n",
    "print('üíª CPU INFO:')\n",
    "print(f'   CPU Cores (Physical): {psutil.cpu_count(logical=False)}')\n",
    "print(f'   CPU Cores (Logical): {psutil.cpu_count(logical=True)}')\n",
    "print(f'   CPU Freq: {psutil.cpu_freq().current:.0f} MHz' if psutil.cpu_freq() else '   CPU Freq: N/A')\n",
    "print()\n",
    "\n",
    "# Memory Info\n",
    "memory = psutil.virtual_memory()\n",
    "print('üíæ MEMORY INFO:')\n",
    "print(f'   Total RAM: {memory.total / 1024**3:.1f} GB')\n",
    "print(f'   Available: {memory.available / 1024**3:.1f} GB')\n",
    "print(f'   Used: {memory.percent}%')\n",
    "print()\n",
    "\n",
    "# Force CPU device\n",
    "device = torch.device('cpu')\n",
    "print(f'üéÆ Using device: {device}')\n",
    "print('‚ö†Ô∏è  Training on CPU - This will be slower than GPU')\n",
    "\n",
    "# Set number of threads for PyTorch\n",
    "num_threads = psutil.cpu_count(logical=True)\n",
    "torch.set_num_threads(num_threads)\n",
    "print(f'üîß PyTorch threads: {num_threads}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e316e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, \n",
    "    classification_report, confusion_matrix, f1_score\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =====================================================\n",
    "# CPU MONITORING FUNCTIONS\n",
    "# =====================================================\n",
    "def get_cpu_memory_usage():\n",
    "    \"\"\"Get current CPU/RAM memory usage\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_mb = process.memory_info().rss / 1024**2\n",
    "    return memory_mb\n",
    "\n",
    "def get_system_stats():\n",
    "    \"\"\"Get comprehensive system stats\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return {\n",
    "        'cpu_percent': psutil.cpu_percent(interval=0.1),\n",
    "        'memory_used_mb': process.memory_info().rss / 1024**2,\n",
    "        'memory_percent': process.memory_percent(),\n",
    "        'system_memory_percent': psutil.virtual_memory().percent\n",
    "    }\n",
    "\n",
    "class CPUMonitor:\n",
    "    \"\"\"Monitor CPU/RAM usage during training\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.memory_samples = []\n",
    "        self.cpu_samples = []\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "    \n",
    "    def start(self):\n",
    "        self.reset()\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Take a sample of current system stats\"\"\"\n",
    "        stats = get_system_stats()\n",
    "        self.memory_samples.append(stats['memory_used_mb'])\n",
    "        self.cpu_samples.append(stats['cpu_percent'])\n",
    "    \n",
    "    def stop(self):\n",
    "        self.end_time = time.time()\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get summary of resource usage\"\"\"\n",
    "        summary = {\n",
    "            'duration_seconds': 0,\n",
    "            'duration_formatted': '0:00:00',\n",
    "            'peak_memory_mb': 0,\n",
    "            'avg_memory_mb': 0,\n",
    "            'avg_cpu_percent': 0,\n",
    "            'max_cpu_percent': 0\n",
    "        }\n",
    "        \n",
    "        if self.start_time and self.end_time:\n",
    "            duration = self.end_time - self.start_time\n",
    "            summary['duration_seconds'] = duration\n",
    "            hours, remainder = divmod(int(duration), 3600)\n",
    "            minutes, seconds = divmod(remainder, 60)\n",
    "            summary['duration_formatted'] = f'{hours}:{minutes:02d}:{seconds:02d}'\n",
    "        \n",
    "        if self.memory_samples:\n",
    "            summary['peak_memory_mb'] = max(self.memory_samples)\n",
    "            summary['avg_memory_mb'] = np.mean(self.memory_samples)\n",
    "        \n",
    "        if self.cpu_samples:\n",
    "            summary['avg_cpu_percent'] = np.mean(self.cpu_samples)\n",
    "            summary['max_cpu_percent'] = max(self.cpu_samples)\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Initialize CPU monitor\n",
    "cpu_monitor = CPUMonitor()\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print('‚úì Libraries imported')\n",
    "print('‚úì CPU monitoring functions defined')\n",
    "print(f'‚úì Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bea17b",
   "metadata": {},
   "source": [
    "## üìä 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data dari folder data/\n",
    "DATA_PATH = 'data/gojek_reviews_final_augmented.csv'\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f'‚ùå File tidak ditemukan: {DATA_PATH}')\n",
    "    print('\\nüìÅ Files yang ada:')\n",
    "    if os.path.exists('data'):\n",
    "        for f in os.listdir('data'):\n",
    "            print(f'   - data/{f}')\n",
    "else:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    \n",
    "    print('=' * 60)\n",
    "    print('üìä DATA OVERVIEW')\n",
    "    print('=' * 60)\n",
    "    print(f'Total samples: {len(df):,}')\n",
    "    print(f'Columns: {df.columns.tolist()}')\n",
    "    print(f'\\nüìà Sentiment Distribution:')\n",
    "    print(df['sentiment'].value_counts())\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    colors = {'negative': '#e74c3c', 'neutral': '#95a5a6', 'positive': '#2ecc71'}\n",
    "    counts = df['sentiment'].value_counts()\n",
    "    bars = ax.bar(counts.index, counts.values, color=[colors[s] for s in counts.index])\n",
    "    ax.set_title('Sentiment Distribution')\n",
    "    ax.set_ylabel('Count')\n",
    "    for bar, count in zip(bars, counts.values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, \n",
    "                str(count), ha='center', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc570a",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è 3. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is already balanced\n",
    "counts = df['sentiment'].value_counts()\n",
    "min_count = counts.min()\n",
    "max_count = counts.max()\n",
    "\n",
    "if (max_count - min_count) / max_count < 0.1:\n",
    "    print('‚úì Data sudah balanced!')\n",
    "    df_balanced = df.copy()\n",
    "else:\n",
    "    print('‚ö†Ô∏è Melakukan undersampling...')\n",
    "    df_balanced = pd.DataFrame()\n",
    "    for sentiment in ['negative', 'neutral', 'positive']:\n",
    "        df_class = df[df['sentiment'] == sentiment]\n",
    "        df_sampled = resample(df_class, replace=False, n_samples=min_count, random_state=42)\n",
    "        df_balanced = pd.concat([df_balanced, df_sampled])\n",
    "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f'\\nüìä Data untuk training: {len(df_balanced):,} samples')\n",
    "print(df_balanced['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16313afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping\n",
    "LABEL_MAP = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "LABEL_NAMES = ['negative', 'neutral', 'positive']\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "df_balanced['label'] = df_balanced['sentiment'].map(LABEL_MAP)\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_balanced, test_size=0.3, random_state=42, stratify=df_balanced['label']\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, random_state=42, stratify=temp_df['label']\n",
    ")\n",
    "\n",
    "print('=' * 60)\n",
    "print('üìÇ DATA SPLITS')\n",
    "print('=' * 60)\n",
    "print(f'Train: {len(train_df):,} samples ({len(train_df)/len(df_balanced)*100:.1f}%)')\n",
    "print(f'Val:   {len(val_df):,} samples ({len(val_df)/len(df_balanced)*100:.1f}%)')\n",
    "print(f'Test:  {len(test_df):,} samples ({len(test_df)/len(df_balanced)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6bac61",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 4. Configuration (CPU Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HYPERPARAMETERS ===\n",
    "# Optimized untuk CPU Training - 10 Epochs\n",
    "\n",
    "CONFIG = {\n",
    "    # Model\n",
    "    'model_name': 'indobenchmark/indobert-base-p1',\n",
    "    'max_length': 128,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    \n",
    "    # Training - CPU Optimized\n",
    "    'batch_size': 16,  # Smaller batch for CPU\n",
    "    'epochs': 10,      # 10 epochs only\n",
    "    'learning_rate': 2e-5,\n",
    "    \n",
    "    # Anti-Overfitting\n",
    "    'dropout_rate': 0.5,\n",
    "    'attention_dropout': 0.2,\n",
    "    'weight_decay': 0.01,\n",
    "    'label_smoothing': 0.1,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'early_stopping_patience': 5,\n",
    "    \n",
    "    # Data Augmentation\n",
    "    'word_dropout_prob': 0.15,\n",
    "    \n",
    "    # Layer Freezing - More aggressive for CPU\n",
    "    'freeze_layers': 10,  # Freeze 10 dari 12 layer untuk speed\n",
    "    \n",
    "    # R-Drop\n",
    "    'rdrop_alpha': 0.3,\n",
    "}\n",
    "\n",
    "print('=' * 60)\n",
    "print('‚öôÔ∏è  CONFIGURATION - CPU MODE')\n",
    "print('=' * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f'{key}: {value}')\n",
    "\n",
    "# Estimate training time\n",
    "print('\\n‚è±Ô∏è  ESTIMATED TRAINING TIME:')\n",
    "print('   With CPU, expect ~5-15 minutes per epoch')\n",
    "print(f'   Total estimated: ~{CONFIG[\"epochs\"] * 10} - {CONFIG[\"epochs\"] * 15} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c362a5fd",
   "metadata": {},
   "source": [
    "## üì¶ 5. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a193de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "print(f'‚úì Tokenizer loaded: {CONFIG[\"model_name\"]}')\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"Dataset dengan augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128, \n",
    "                 augment=False, word_dropout_prob=0.15):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.augment = augment\n",
    "        self.word_dropout_prob = word_dropout_prob\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def _augment_text(self, text):\n",
    "        if not self.augment:\n",
    "            return text\n",
    "        \n",
    "        text = str(text)\n",
    "        words = text.split()\n",
    "        \n",
    "        if len(words) <= 3:\n",
    "            return text\n",
    "        \n",
    "        aug_type = random.random()\n",
    "        \n",
    "        if aug_type < 0.3:\n",
    "            # Word dropout\n",
    "            words = [w for w in words if random.random() > self.word_dropout_prob]\n",
    "        elif aug_type < 0.5:\n",
    "            # Word swap\n",
    "            if len(words) > 2:\n",
    "                idx = random.randint(0, len(words) - 2)\n",
    "                words[idx], words[idx + 1] = words[idx + 1], words[idx]\n",
    "        \n",
    "        return ' '.join(words) if words else text\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self._augment_text(self.texts[idx])\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            str(text),\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73717458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = SentimentDataset(\n",
    "    train_df['content_clean'].values,\n",
    "    train_df['label'].values,\n",
    "    tokenizer,\n",
    "    max_length=CONFIG['max_length'],\n",
    "    augment=True,\n",
    "    word_dropout_prob=CONFIG['word_dropout_prob']\n",
    ")\n",
    "\n",
    "val_dataset = SentimentDataset(\n",
    "    val_df['content_clean'].values,\n",
    "    val_df['label'].values,\n",
    "    tokenizer,\n",
    "    max_length=CONFIG['max_length'],\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "test_dataset = SentimentDataset(\n",
    "    test_df['content_clean'].values,\n",
    "    test_df['label'].values,\n",
    "    tokenizer,\n",
    "    max_length=CONFIG['max_length'],\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "# Create dataloaders - num_workers=0 for CPU\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, \n",
    "                          drop_last=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "\n",
    "print(f'\\n‚úì Datasets created:')\n",
    "print(f'  Train: {len(train_dataset)} samples, {len(train_loader)} batches')\n",
    "print(f'  Val:   {len(val_dataset)} samples, {len(val_loader)} batches')\n",
    "print(f'  Test:  {len(test_dataset)} samples, {len(test_loader)} batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200aa6fd",
   "metadata": {},
   "source": [
    "## üß† 6. Model (CPU Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ff0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndoBERTSentimentClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    IndoBERT dengan optimisasi untuk CPU:\n",
    "    - Freeze lebih banyak layer (10/12)\n",
    "    - Simple classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name, num_classes, dropout_rate=0.5, \n",
    "                 attention_dropout=0.2, freeze_layers=10):\n",
    "        super(IndoBERTSentimentClassifier, self).__init__()\n",
    "        \n",
    "        # Load pretrained BERT\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # Freeze embeddings\n",
    "        for param in self.bert.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Freeze first N encoder layers (more for CPU)\n",
    "        for i in range(freeze_layers):\n",
    "            for param in self.bert.encoder.layer[i].parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        print(f'‚úì Froze embeddings and first {freeze_layers} encoder layers')\n",
    "        print(f'  Only layers {freeze_layers}-11 are trainable ({12-freeze_layers} layers)')\n",
    "        \n",
    "        # Regularization\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.layer_norm = nn.LayerNorm(self.hidden_size)\n",
    "        \n",
    "        # Simple classifier\n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes)\n",
    "        \n",
    "        # Initialize\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.layer_norm(pooled_output)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print('Loading IndoBERT model (this may take a moment on CPU)...')\n",
    "model = IndoBERTSentimentClassifier(\n",
    "    model_name=CONFIG['model_name'],\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    dropout_rate=CONFIG['dropout_rate'],\n",
    "    attention_dropout=CONFIG['attention_dropout'],\n",
    "    freeze_layers=CONFIG['freeze_layers']\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "print(f'\\n‚úì Model loaded to {device}')\n",
    "print(f'  Total parameters: {total_params:,}')\n",
    "print(f'  Trainable: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)')\n",
    "print(f'  Frozen: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)')\n",
    "print(f'\\nüí° Fewer trainable params = Faster CPU training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86100ed4",
   "metadata": {},
   "source": [
    "## üìâ 7. Loss, Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function dengan label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=CONFIG['label_smoothing'])\n",
    "\n",
    "# Optimizer - hanya untuk trainable parameters\n",
    "no_decay = ['bias', 'LayerNorm.weight', 'layer_norm.weight']\n",
    "trainable_params_list = [(n, p) for n, p in model.named_parameters() if p.requires_grad]\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in trainable_params_list if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': CONFIG['weight_decay']\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in trainable_params_list if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=CONFIG['learning_rate'])\n",
    "\n",
    "# Scheduler\n",
    "total_steps = len(train_loader) * CONFIG['epochs']\n",
    "warmup_steps = int(total_steps * CONFIG['warmup_ratio'])\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f'‚úì Optimizer: AdamW (lr={CONFIG[\"learning_rate\"]}, wd={CONFIG[\"weight_decay\"]})')\n",
    "print(f'‚úì Scheduler: Linear warmup ({warmup_steps} warmup, {total_steps} total)')\n",
    "print(f'‚úì Loss: CrossEntropy with label_smoothing={CONFIG[\"label_smoothing\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9bb9fd",
   "metadata": {},
   "source": [
    "## üèãÔ∏è 8. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f436014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kl_loss(p, q):\n",
    "    \"\"\"KL divergence for R-Drop\"\"\"\n",
    "    p_loss = F.kl_div(F.log_softmax(p, dim=-1), F.softmax(q, dim=-1), reduction='batchmean')\n",
    "    q_loss = F.kl_div(F.log_softmax(q, dim=-1), F.softmax(p, dim=-1), reduction='batchmean')\n",
    "    return (p_loss + q_loss) / 2\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, scheduler, device, \n",
    "                max_grad_norm, rdrop_alpha=0.3):\n",
    "    \"\"\"Train dengan R-Drop regularization\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Training', leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # R-Drop: 2 forward passes\n",
    "        logits1 = model(input_ids, attention_mask)\n",
    "        logits2 = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Cross entropy loss\n",
    "        ce_loss = (criterion(logits1, labels) + criterion(logits2, labels)) / 2\n",
    "        \n",
    "        # KL divergence loss\n",
    "        kl_loss = compute_kl_loss(logits1, logits2)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = ce_loss + rdrop_alpha * kl_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        avg_logits = (logits1 + logits2) / 2\n",
    "        preds = torch.argmax(avg_logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping dengan gap monitoring\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=5, min_delta=0.001, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "    \n",
    "    def __call__(self, score, model):\n",
    "        if self.mode == 'max':\n",
    "            is_improvement = self.best_score is None or score > self.best_score + self.min_delta\n",
    "        else:\n",
    "            is_improvement = self.best_score is None or score < self.best_score - self.min_delta\n",
    "        \n",
    "        if is_improvement:\n",
    "            self.best_score = score\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        \n",
    "        return self.early_stop\n",
    "\n",
    "print('‚úì Training functions defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113d4ee",
   "metadata": {},
   "source": [
    "## üöÄ 9. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b269cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
    "    'gap': [],\n",
    "    'epoch_time': [],\n",
    "    'memory_used_mb': [],\n",
    "    'cpu_percent': []\n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=CONFIG['early_stopping_patience'], \n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "print('=' * 60)\n",
    "print('üöÄ TRAINING STARTED - CPU MODE')\n",
    "print('=' * 60)\n",
    "print(f'Device: {device}')\n",
    "print(f'Epochs: {CONFIG[\"epochs\"]} | Patience: {CONFIG[\"early_stopping_patience\"]}')\n",
    "print(f'LR: {CONFIG[\"learning_rate\"]} | Batch: {CONFIG[\"batch_size\"]}')\n",
    "print(f'Frozen Layers: {CONFIG[\"freeze_layers\"]}/12 | Dropout: {CONFIG[\"dropout_rate\"]}')\n",
    "print('-' * 60)\n",
    "\n",
    "# Show initial system stats\n",
    "stats = get_system_stats()\n",
    "print(f'üíª CPU Usage: {stats[\"cpu_percent\"]:.1f}%')\n",
    "print(f'üíæ Memory: {stats[\"memory_used_mb\"]:.0f} MB ({stats[\"memory_percent\"]:.1f}%)')\n",
    "print('-' * 60)\n",
    "\n",
    "best_val_f1 = 0\n",
    "best_epoch = 0\n",
    "best_gap = float('inf')\n",
    "\n",
    "# Start CPU monitoring\n",
    "cpu_monitor.start()\n",
    "training_start_time = datetime.now()\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "    print(f'\\nüìç Epoch {epoch + 1}/{CONFIG[\"epochs\"]}')\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc, train_f1 = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, scheduler, \n",
    "        device, CONFIG['max_grad_norm'], CONFIG['rdrop_alpha']\n",
    "    )\n",
    "    \n",
    "    # Sample CPU stats after training\n",
    "    cpu_monitor.sample()\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_f1, _, _ = evaluate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    gap = train_acc - val_acc\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Get current system stats\n",
    "    current_stats = get_system_stats()\n",
    "    current_memory = current_stats['memory_used_mb']\n",
    "    current_cpu = current_stats['cpu_percent']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    history['gap'].append(gap)\n",
    "    history['epoch_time'].append(epoch_time)\n",
    "    history['memory_used_mb'].append(current_memory)\n",
    "    history['cpu_percent'].append(current_cpu)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f'  Train - Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}')\n",
    "    print(f'  Val   - Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Track best\n",
    "    if val_f1 > best_val_f1 and gap < 0.10:\n",
    "        best_val_f1 = val_f1\n",
    "        best_epoch = epoch + 1\n",
    "        best_gap = gap\n",
    "        print(f'  ‚≠ê New best! F1: {val_f1:.4f}, Gap: {gap*100:.2f}%')\n",
    "    \n",
    "    # Gap status\n",
    "    gap_status = '‚úÖ Good' if gap < 0.05 else '‚ö° OK' if gap < 0.10 else '‚ö†Ô∏è High'\n",
    "    print(f'  üìä Gap: {gap*100:.2f}% {gap_status}')\n",
    "    print(f'  ‚è±Ô∏è  Time: {epoch_time:.1f}s | üíæ RAM: {current_memory:.0f}MB | üíª CPU: {current_cpu:.1f}%')\n",
    "    \n",
    "    # Early stopping\n",
    "    if early_stopping(val_f1, model):\n",
    "        print(f'\\nüõë Early stopping at epoch {epoch + 1}')\n",
    "        break\n",
    "\n",
    "# Stop CPU monitoring\n",
    "cpu_monitor.stop()\n",
    "training_end_time = datetime.now()\n",
    "total_time = training_end_time - training_start_time\n",
    "\n",
    "# Load best model\n",
    "if early_stopping.best_model is not None:\n",
    "    model.load_state_dict(early_stopping.best_model)\n",
    "\n",
    "# Get CPU summary\n",
    "cpu_summary = cpu_monitor.get_summary()\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('‚úÖ TRAINING COMPLETED')\n",
    "print('=' * 60)\n",
    "print(f'  Best epoch: {best_epoch}')\n",
    "print(f'  Best Val F1: {best_val_f1:.4f}')\n",
    "print(f'  Best Gap: {best_gap*100:.2f}%')\n",
    "print()\n",
    "print('‚è±Ô∏è  TIME STATISTICS:')\n",
    "print(f'  Total Duration: {cpu_summary[\"duration_formatted\"]}')\n",
    "print(f'  Avg Time/Epoch: {np.mean(history[\"epoch_time\"]):.1f}s')\n",
    "print()\n",
    "print('üíæ MEMORY STATISTICS:')\n",
    "print(f'  Peak RAM: {cpu_summary[\"peak_memory_mb\"]:.0f} MB')\n",
    "print(f'  Avg RAM: {cpu_summary[\"avg_memory_mb\"]:.0f} MB')\n",
    "print()\n",
    "print('üíª CPU STATISTICS:')\n",
    "print(f'  Avg CPU Usage: {cpu_summary[\"avg_cpu_percent\"]:.1f}%')\n",
    "print(f'  Max CPU Usage: {cpu_summary[\"max_cpu_percent\"]:.1f}%')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e655b6",
   "metadata": {},
   "source": [
    "## üìà 10. Training Visualization & Resource Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac466235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# FIGURE 1: Training Metrics\n",
    "# =====================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(epochs_range, history['train_loss'], 'b-o', label='Train', markersize=6)\n",
    "axes[0, 0].plot(epochs_range, history['val_loss'], 'r-s', label='Val', markersize=6)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training & Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(epochs_range, history['train_acc'], 'b-o', label='Train', markersize=6)\n",
    "axes[0, 1].plot(epochs_range, history['val_acc'], 'r-s', label='Val', markersize=6)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].set_title('Training & Validation Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "axes[1, 0].plot(epochs_range, history['train_f1'], 'b-o', label='Train', markersize=6)\n",
    "axes[1, 0].plot(epochs_range, history['val_f1'], 'r-s', label='Val', markersize=6)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('F1 Score')\n",
    "axes[1, 0].set_title('Training & Validation F1 Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gap\n",
    "axes[1, 1].plot(epochs_range, [g*100 for g in history['gap']], 'g-o', markersize=6)\n",
    "axes[1, 1].axhline(y=5, color='orange', linestyle='--', label='Good threshold (5%)')\n",
    "axes[1, 1].axhline(y=10, color='red', linestyle='--', label='Warning threshold (10%)')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Train-Val Gap (%)')\n",
    "axes[1, 1].set_title('Overfitting Monitor (Train-Val Gap)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_cpu.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('‚úì Saved: training_history_cpu.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcbc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# FIGURE 2: Resource Usage (Time, Memory, CPU)\n",
    "# =====================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "epochs_range = range(1, len(history['epoch_time']) + 1)\n",
    "\n",
    "# Time per epoch\n",
    "axes[0, 0].bar(epochs_range, history['epoch_time'], color='steelblue', alpha=0.7)\n",
    "axes[0, 0].axhline(y=np.mean(history['epoch_time']), color='red', linestyle='--', \n",
    "                   label=f'Avg: {np.mean(history[\"epoch_time\"]):.1f}s')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Time (seconds)')\n",
    "axes[0, 0].set_title('‚è±Ô∏è Training Time per Epoch')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Memory usage (RAM)\n",
    "axes[0, 1].plot(epochs_range, history['memory_used_mb'], 'purple', marker='o', markersize=6)\n",
    "axes[0, 1].axhline(y=cpu_summary['peak_memory_mb'], color='red', linestyle='--', \n",
    "                   label=f'Peak: {cpu_summary[\"peak_memory_mb\"]:.0f} MB')\n",
    "axes[0, 1].fill_between(epochs_range, 0, history['memory_used_mb'], alpha=0.3, color='purple')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Memory (MB)')\n",
    "axes[0, 1].set_title('üíæ RAM Usage')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# CPU usage\n",
    "axes[1, 0].plot(epochs_range, history['cpu_percent'], 'orange', marker='s', markersize=6)\n",
    "axes[1, 0].axhline(y=cpu_summary['avg_cpu_percent'], color='red', linestyle='--', \n",
    "                   label=f'Avg: {cpu_summary[\"avg_cpu_percent\"]:.1f}%')\n",
    "axes[1, 0].fill_between(epochs_range, 0, history['cpu_percent'], alpha=0.3, color='orange')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('CPU Usage (%)')\n",
    "axes[1, 0].set_title('üíª CPU Usage')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Summary statistics as text\n",
    "axes[1, 1].axis('off')\n",
    "summary_text = f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë      üìä CPU TRAINING RESOURCE SUMMARY        ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                              ‚ïë\n",
    "‚ïë  ‚è±Ô∏è  TIME STATISTICS                         ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Total Duration: {cpu_summary['duration_formatted']:>20}  ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Total Seconds:  {cpu_summary['duration_seconds']:>17.1f}s  ‚ïë\n",
    "‚ïë  ‚îî‚îÄ Avg per Epoch:  {np.mean(history['epoch_time']):>17.1f}s  ‚ïë\n",
    "‚ïë                                              ‚ïë\n",
    "‚ïë  üíæ RAM STATISTICS                           ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Peak Memory:    {cpu_summary['peak_memory_mb']:>15.0f} MB  ‚ïë\n",
    "‚ïë  ‚îî‚îÄ Avg Memory:     {cpu_summary['avg_memory_mb']:>15.0f} MB  ‚ïë\n",
    "‚ïë                                              ‚ïë\n",
    "‚ïë  üíª CPU STATISTICS                           ‚ïë\n",
    "‚ïë  ‚îú‚îÄ Avg Usage:      {cpu_summary['avg_cpu_percent']:>16.1f}%  ‚ïë\n",
    "‚ïë  ‚îî‚îÄ Max Usage:      {cpu_summary['max_cpu_percent']:>16.1f}%  ‚ïë\n",
    "‚ïë                                              ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\"\n",
    "axes[1, 1].text(0.1, 0.5, summary_text, fontsize=11, fontfamily='monospace',\n",
    "                verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('resource_usage_cpu.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('‚úì Saved: resource_usage_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2de5ae",
   "metadata": {},
   "source": [
    "## üß™ 11. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print('=' * 60)\n",
    "print('üß™ TEST SET EVALUATION')\n",
    "print('=' * 60)\n",
    "print(f'Test Accuracy: {test_acc*100:.2f}%')\n",
    "print(f'Test F1 Score: {test_f1*100:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Classification report\n",
    "print('\\nüìä Classification Report:')\n",
    "print(classification_report(test_labels, test_preds, target_names=LABEL_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=LABEL_NAMES, yticklabels=LABEL_NAMES, ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('Confusion Matrix (Counts)')\n",
    "\n",
    "# Percentages\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.1f', cmap='Blues',\n",
    "            xticklabels=LABEL_NAMES, yticklabels=LABEL_NAMES, ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_title('Confusion Matrix (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_cpu.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('‚úì Saved: confusion_matrix_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3716569",
   "metadata": {},
   "source": [
    "## üíæ 12. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = 'models/indobert_sentiment_3class_cpu.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'label_map': LABEL_MAP,\n",
    "    'label_names': LABEL_NAMES,\n",
    "    'test_accuracy': test_acc,\n",
    "    'test_f1': test_f1,\n",
    "    'best_val_f1': best_val_f1,\n",
    "    'best_gap': best_gap,\n",
    "    'history': history,\n",
    "    'training_device': 'cpu'\n",
    "}, model_path)\n",
    "print(f'‚úì Model saved: {model_path}')\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained('models/tokenizer')\n",
    "print(f'‚úì Tokenizer saved: models/tokenizer/')\n",
    "\n",
    "# Save history\n",
    "with open('models/training_history_cpu.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(f'‚úì History saved: models/training_history_cpu.json')\n",
    "\n",
    "# List saved files\n",
    "print('\\nüìÅ Saved files:')\n",
    "for root, dirs, files in os.walk('models'):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file)\n",
    "        size = os.path.getsize(filepath) / (1024*1024)\n",
    "        print(f'   {filepath} ({size:.2f} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1815e6",
   "metadata": {},
   "source": [
    "## üîÆ 13. Inference Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84081af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device, label_names):\n",
    "    \"\"\"Predict sentiment untuk satu teks\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "    \n",
    "    return {\n",
    "        'sentiment': label_names[pred],\n",
    "        'confidence': probs[0][pred].item(),\n",
    "        'probabilities': {\n",
    "            label_names[i]: probs[0][i].item() \n",
    "            for i in range(len(label_names))\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test\n",
    "test_reviews = [\n",
    "    \"Aplikasi gojek sangat membantu, driver ramah dan cepat\",\n",
    "    \"Driver nya lama banget, udah nunggu 1 jam gak datang\",\n",
    "    \"Biasa aja sih aplikasinya\",\n",
    "    \"Pelayanan buruk, tidak akan pakai lagi\",\n",
    "    \"Mantap, makanan sampai dengan selamat dan masih hangat\",\n",
    "]\n",
    "\n",
    "print('=' * 60)\n",
    "print('üîÆ INFERENCE DEMO')\n",
    "print('=' * 60)\n",
    "\n",
    "for review in test_reviews:\n",
    "    result = predict_sentiment(review, model, tokenizer, device, LABEL_NAMES)\n",
    "    emoji = {'negative': 'üò†', 'neutral': 'üòê', 'positive': 'üòä'}[result['sentiment']]\n",
    "    print(f'\\nüìù \"{review[:50]}...\"' if len(review) > 50 else f'\\nüìù \"{review}\"')\n",
    "    print(f'   {emoji} {result[\"sentiment\"].upper()} ({result[\"confidence\"]*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed6629",
   "metadata": {},
   "source": [
    "## üìä 14. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gap = history['train_acc'][-1] - history['val_acc'][-1]\n",
    "min_gap = min(history['gap'])\n",
    "\n",
    "print('=' * 70)\n",
    "print('üìä FINAL TRAINING SUMMARY - CPU MODE')\n",
    "print('=' * 70)\n",
    "\n",
    "print(f'''\n",
    "üéØ MODEL PERFORMANCE:\n",
    "   ‚Ä¢ Test Accuracy: {test_acc*100:.2f}%\n",
    "   ‚Ä¢ Test F1 Score: {test_f1*100:.2f}%\n",
    "   ‚Ä¢ Best Val F1: {best_val_f1*100:.2f}%\n",
    "\n",
    "üìà OVERFITTING CHECK:\n",
    "   ‚Ä¢ Final Gap: {final_gap*100:.2f}%\n",
    "   ‚Ä¢ Best Gap: {best_gap*100:.2f}%\n",
    "   ‚Ä¢ Status: {\"‚úÖ Good\" if final_gap < 0.05 else \"‚ö†Ô∏è Check\" if final_gap < 0.10 else \"‚ùå Overfitting\"}\n",
    "\n",
    "‚è±Ô∏è  TIME & RESOURCE USAGE:\n",
    "   ‚Ä¢ Total Training Time: {cpu_summary['duration_formatted']}\n",
    "   ‚Ä¢ Average Time per Epoch: {np.mean(history['epoch_time']):.1f} seconds\n",
    "   ‚Ä¢ Peak RAM Usage: {cpu_summary['peak_memory_mb']:.0f} MB\n",
    "   ‚Ä¢ Average RAM Usage: {cpu_summary['avg_memory_mb']:.0f} MB\n",
    "   ‚Ä¢ Average CPU Usage: {cpu_summary['avg_cpu_percent']:.1f}%\n",
    "   ‚Ä¢ Max CPU Usage: {cpu_summary['max_cpu_percent']:.1f}%\n",
    "\n",
    "‚öôÔ∏è CONFIGURATION:\n",
    "   ‚Ä¢ Device: CPU\n",
    "   ‚Ä¢ Epochs: {CONFIG['epochs']}\n",
    "   ‚Ä¢ Batch Size: {CONFIG['batch_size']}\n",
    "   ‚Ä¢ Layer Freezing: {CONFIG['freeze_layers']}/12\n",
    "   ‚Ä¢ Dropout: {CONFIG['dropout_rate']}\n",
    "   ‚Ä¢ Learning Rate: {CONFIG['learning_rate']}\n",
    "\n",
    "üíæ SAVED FILES:\n",
    "   ‚Ä¢ models/indobert_sentiment_3class_cpu.pt\n",
    "   ‚Ä¢ models/tokenizer/\n",
    "   ‚Ä¢ models/training_history_cpu.json\n",
    "   ‚Ä¢ training_history_cpu.png\n",
    "   ‚Ä¢ resource_usage_cpu.png\n",
    "   ‚Ä¢ confusion_matrix_cpu.png\n",
    "''')\n",
    "\n",
    "if test_acc >= 0.70 and final_gap < 0.05:\n",
    "    print('üéâ GOOD! Model has decent accuracy and generalization for CPU training!')\n",
    "elif test_acc >= 0.70:\n",
    "    print('‚ö†Ô∏è Decent accuracy but watch for overfitting.')\n",
    "elif final_gap < 0.05:\n",
    "    print('‚úÖ Good generalization but accuracy could improve with more epochs.')\n",
    "else:\n",
    "    print('üí° Consider more epochs or adjusting hyperparameters.')\n",
    "\n",
    "print('=' * 70)\n",
    "print('‚úÖ CPU Training completed!')\n",
    "print('=' * 70)\n",
    "\n",
    "# Save complete training report\n",
    "training_report = {\n",
    "    'training_mode': 'CPU',\n",
    "    'model_performance': {\n",
    "        'test_accuracy': float(test_acc),\n",
    "        'test_f1_score': float(test_f1),\n",
    "        'best_val_f1': float(best_val_f1),\n",
    "        'best_epoch': best_epoch,\n",
    "        'final_gap': float(final_gap),\n",
    "        'best_gap': float(best_gap)\n",
    "    },\n",
    "    'resource_usage': {\n",
    "        'total_duration_seconds': cpu_summary['duration_seconds'],\n",
    "        'total_duration_formatted': cpu_summary['duration_formatted'],\n",
    "        'avg_epoch_time_seconds': float(np.mean(history['epoch_time'])),\n",
    "        'peak_ram_mb': cpu_summary['peak_memory_mb'],\n",
    "        'avg_ram_mb': cpu_summary['avg_memory_mb'],\n",
    "        'avg_cpu_percent': cpu_summary['avg_cpu_percent'],\n",
    "        'max_cpu_percent': cpu_summary['max_cpu_percent']\n",
    "    },\n",
    "    'config': CONFIG,\n",
    "    'history': history\n",
    "}\n",
    "\n",
    "with open('models/training_report_cpu.json', 'w') as f:\n",
    "    json.dump(training_report, f, indent=2)\n",
    "print('\\n‚úì Complete training report saved: models/training_report_cpu.json')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
